En général, lorsque la [[C - Complexité d'un modèle (capacité)]] augmente, son interprétabilitié diminue ([[C - Interprétabilité]]). 
- Il est donc facile d'expliquer les décisions prises par des modèles simples comme [[A - Régression Linéaire]] ou un [[A - Arbre de décision]].
- On ne peut pas dire la même chose d'un [[A - Réseau de neurones]], pour faire des prédictions avec les données d'entrée sont passées à travers de nombreuses couches et effectuent de nombreux produits matriciels suivis de transformations non-linéaires et donc une seule prédiction implique facilement des millions d'opérations. C'est difficile à interpréter.

