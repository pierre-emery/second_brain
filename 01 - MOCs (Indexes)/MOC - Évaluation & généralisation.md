# 1) Fondations : perte, risque, généralisation
- [[C - Fonction de perte]]
- [[C - Risque]]
- [[C - Risque empirique]]
- [[C - Erreur de généralisation]]

## 2) Biais–variance, complexité, over/underfitting
- [[C - Biais]]
- [[C - Variance (expliquée)]]
- [[C - Compromis Biais-Variance]]
- [[C - Complexité d'un modèle (capacité)]]
- [[C - Surapprentissage]]
- [[C - Sous-apprentissage]]
- [[C - Sélection de modèle]]

## 3) Diagnostic d'entraînement (courbes)
- [[C - Courbe d'apprentissage (loss vs epochs)]]
- [[C - Courbe de métrique (accuracy... vs epochs)]]
- [[C - Early stopping]]

## 4) Métriques de régression
### Pertes (souvent utilisées comme objectifs)
- [[C - Perte quadratique (MSE)]]
- [[C - Racine de l'erreur quadratique (RMSE)]]
- [[C - Erreur absolue moyenne (MAE)]]

### Score (interprétation "qualité d'ajustement")
- [[C - R^2 (coefficient de détermination)]]
- [[C - R^2 ajusté]]

## 5) Métriques de classification
### Perte / erreur
- [[C - Perte 0-1]]

### Matrice de confusion & métriques dérivées
- [[C - Matrice de confusion]]
- [[C - Exactitude (accuracy)]]
- [[C - Précision]]
- [[C - Rappel (sensibilité)]]
- [[C - Spécificité]]
- [[C - TPR & FPR]]
- [[C - Seuil de décision (threshold)]]
- [[C - Courbe ROC & AUC]]
- [[C - Courbe Precision-Recall (PR)]]

## 6) Coûts de calcul : entraînement vs inférence
- [[C - Temps d'entraînement]]
- [[C - Temps d'inférence (latence)]]
- [[C - Compromis entraînement–inférence]]

## 7) Interprétabilité, explicabilité & biais
- [[C - Compromis interprétabilité–performance]]
- [[C - Interprétabilité]]
- [[C - Biais de sélection]]
- [[C - Biais de mesure]]
- [[A - LIME]]
- [[A - SHAP]]
- [[A - DeepLIFT]]
